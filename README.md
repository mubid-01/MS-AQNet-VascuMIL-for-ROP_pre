# üöÄ Note: The complete source code and pretrained weights will be released soon.

# Context-Aware Asymmetric Ensembling for ROP Screening

**Official PyTorch Implementation**

> **Paper Title:** *Context-Aware Asymmetric Ensembling: Integrating Active Query Mechanisms and Vascular Multiple Instance Learning for Interpretable Retinopathy of Prematurity Screening*

---

## 1. Introduction & Motivation

Retinopathy of Prematurity (ROP) is a leading cause of childhood blindness. Automated screening is complicated by the dual nature of the disease:
1.  **Global Structural Anomalies:** Ridges, demarcation lines, and detachments (Stage-based disease).
2.  **Local Micro-Vascular Irregularities:** Arteriolar tortuosity and venous dilation (Plus disease).

Standard Deep Learning approaches often fail on ROP datasets due to **extreme class imbalance**, **limited sample sizes**, and **resolution trade-offs** (downsizing destroys vascular details). Furthermore, most models are "Black Boxes" that ignore critical clinical priors like Gestational Age (GA) and Birth Weight (BW).

### Our Solution: The Asymmetric Ensemble
We propose a novel framework that decouples the diagnostic task into two specialized streams using a **"Resolution Bifurcation"** strategy:

*   **Structure Stream (MS-AQNet):** Operates on global images ($384 \times 384$). Features a novel **Active Query Mechanism** where clinical metadata explicitly "queries" visual feature maps to localize risk-relevant structural pathology.
*   **Texture Stream (VascuMIL):** Operates on high-resolution ($768 \times 768$) patch bags. Utilizes **Vascular Topology Maps (VMAP)** and **Gated Attention MIL** to detect micro-vascular Plus Disease independent of clinical history.

**Key Results (N=188):**
*   **Macro F1 (Diagnosis):** 0.93
*   **ROC AUC (Plus Disease):** 0.999
*   **Severe ROP Sensitivity:** 96.3%

---

## 2. Methodology Overview

### Phase A: Intelligent Data Engineering
We employ a rigorous preprocessing pipeline to standardize data from heterogeneous devices (Clarity, Natus, Phoenix):
*   **Morphological Erosion:** Removes circular aperture artifacts.
*   **Vascular Topology Extraction:** Generates VMAPs using Frangi filters on the Green channel.
*   **4-Channel Stacking:** RGB patches are concatenated depth-wise with VMAPs to enforce geometric awareness in the CNN.

### Phase B: The Structure Specialist (MS-AQNet)
*   **Backbone:** EfficientNet-B0 with **Frozen Batch Normalization** (to stabilize small-batch training).
*   **Active Query:** Clinical metadata is projected into a latent vector that computes spatial attention maps via dot-product similarity.
*   **FiLM Modulation:** Global features are scaled and shifted based on patient risk profiles.

### Phase C: The Texture Specialist (VascuMIL)
*   **Architecture:** Multiple Instance Learning (MIL) with Gated Attention (Ilse et al.).
*   **Input:** Bags of 24 high-resolution patches ($224 \times 224$).
*   **Mechanism:** Assigns attention scores to "sick" patches (tortuosity) while suppressing background noise.

---

## 3. Dataset

This project utilizes the public dataset: **"Retinal Image Dataset of Infants and Retinopathy of Prematurity"** (*Timkoviƒç et al., Scientific Data 2024*).

### Setup
1.  Download the dataset.
2.  Ensure your directory structure looks like this:

```text
/data_root
‚îú‚îÄ‚îÄ images_stack_without_captions/  # Contains raw .jpg images
‚îú‚îÄ‚îÄ splits_balanced/                # Generated by our split script
‚îÇ   ‚îú‚îÄ‚îÄ fold_0/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ val.csv
‚îÇ   ‚îî‚îÄ‚îÄ test.csv
‚îî‚îÄ‚îÄ mil_dataset_fold0/              # Generated by our extractor script
    ‚îú‚îÄ‚îÄ images/                     # Cached patches
    ‚îî‚îÄ‚îÄ metadata/                   # Patch CSVs


```
## 4. Training Pipeline

To reproduce the results reported in the paper, follow these three phases in order.

### Phase A: Train the Structure Specialist (MS-AQNet)
Trains the Multi-Scale Active Query Network using Clinical Focal Loss and a "Bulldog" weighting scheme to prioritize Severe ROP cases.

```bash
python engine_ms_aqnet_production.py \
  --fold 0 \
  --epochs 30 \
  --batch_size 16 \
  --lr_head 1e-3 \
  --lr_backbone 1e-6 \
  --freeze_backbone_epochs 5 \
  --use_sampler \
  --out_dir ./ms_models_restored_final
```

### Phase B: Train the Texture Specialist (VascuMIL)
Trains the 4-Channel (RGB+VMAP) MIL network. Uses a Bag-Level Weighted Sampler to handle the rarity of Plus Disease (~3% prevalence) and BCEWithLogitsLoss.

```bash
python engine_mil_production.py \
  --train_csv ./mil_dataset_fold0/metadata/fold_0/patches_train.csv \
  --val_csv ./mil_dataset_fold0/metadata/fold_0/patches_val.csv \
  --cache_root ./mil_dataset_fold0/images \
  --bag_size 24 \
  --batch_size 4 \
  --epochs 20 \
  --static_pos_weight 1.0 \
  --out_dir ./mil_models
```

### Phase C: Train the Fusion Ensemble
Freezes the two specialists and trains a lightweight Meta-Learner (MLP) on the validation set predictions (Stacking strategy) to learn the optimal combination of Structure, Texture, and Metadata.

```bash
python engine_ensemble.py \
  --ms_path ./ms_models_restored_final/best_ms_clinical.pth \
  --mil_path ./mil_models/best_mil_model.pth \
  --val_csv ./splits_balanced/fold_0/val.csv \
  --patches_csv ./mil_dataset_fold0/metadata/fold_0/patches_val.csv
```

**Output:** Saves `final_fusion_ensemble.pth` and prints final SOTA metrics (F1, Kappa, AUC).

## 5. Repository Structure

### Data Engineering
- `balanced_split_by_diagnosis_with_plus_fix.py`: A robust splitter that handles extreme class imbalance, ensuring every fold contains rare classes (Severe/Plus).
- `preproc_shared.py`: The "Source of Truth" for image processing (Gamma ‚Üí Erosion ‚Üí CLAHE).
- `patch_extractor_optimized.py`: Generates VMAPs (Frangi) and extracts high-res patches.

### Modeling
- `model_ms_aqnet.py`: Defines MS-AQNet (Structure), featuring the Active Query Unit and FiLM layers.
- `model_patch_mil.py`: Defines VascuMIL (Texture), featuring 4-channel inputs and Gated Attention.
- `model_ensemble.py`: Defines the Fusion MLP.

### Training Engines
- `dataset_loader_ms_aqnet.py`: PyTorch loader for MS-AQNet (includes aggressive augmentation).
- `mil_dataloader_rgb_vmap.py`: PyTorch loader for VascuMIL (handles bag construction).
- `engine_ms_aqnet_production.py`: Training loop for Structure stream.
- `engine_mil_production.py`: Training loop for Texture stream.
- `engine_ensemble.py`: Training loop for Fusion.

## 6. Clinical Explainability ("Glass Box")

This framework includes a suite of visualization tools to validate model decision-making against clinical landmarks.

| Script Name | Paper Figure | Function |
|-------------|--------------|----------|
| `viz_ms_aqnet_explainability.py` | Figure 2 | Generates Grad-CAM++ Heatmaps and "Counterfactual Risk Maps" showing how metadata alters visual attention. |
| `viz_mil_vessel_map_fixed.py` | Figure 3 | Reconstructs a full-image "Vascular Threat Map" (Neon style) by reprojecting patch attention scores. |
| `viz_combined_explainability.py` | Figure 4 | Generates composite case studies (Original + Structure Map + Texture Map) side-by-side. |
| `viz_confusion_matrix_dual.py` | Figure 6 | Plots the dual-panel confusion matrix for Broad Diagnosis and Plus Disease. |
| `viz_shap_tsne.py` | Figure 7 | Generates SHAP Beeswarm plots and t-SNE manifold projections. |

To generate the main explainability figure:
```bash
python viz_combined_explainability.py
```

## Acknowledgments
We thank the authors of the Scientific Data ROP dataset (Timkoviƒç et al.) for making their data publicly available.
```
